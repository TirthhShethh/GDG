{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TirthhShethh/GDG/blob/main/GDG_Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GDG TASK 1**\n",
        "\n",
        "\n",
        "Welcome to GDG!\n",
        "\n",
        "Your first task in this committee is to clear your Exploratory Data Analysis (EDA) concepts. We'll start from the very basics, and make it just a teeny lil bit more complex with every next code cell.\n",
        "\n",
        "I suppose a nice place to start with would be the definition of EDA. Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns, to spot anomalies, to test hypothesis and to check assumptions with the help of summary statistics and graphical representations. It is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualisation methods.\n",
        "\n",
        "Above each code cell, instructions and resources have been given. Go through the resources, then implement the code accordingly. Feel free to add extra cells to play around on your own as well :p"
      ],
      "metadata": {
        "id": "dx6zRq_3dVgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#installing libraries and importing them"
      ],
      "metadata": {
        "id": "JF_1_88JgaFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some libraries like numpy and pandas are already pre installed on Colab. Some need to explicitly installed. A really cool data exploration library called ydata-profiling falls in the latter category. So we use the appropriate pip command to install it."
      ],
      "metadata": {
        "id": "peb67dMAkMg-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORep3J4JePys"
      },
      "outputs": [],
      "source": [
        "# Install ydata-profiling for automated EDA\n",
        "!pip install ydata-profiling -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount your Google Drive onto this notebook."
      ],
      "metadata": {
        "id": "Nu6t8LW8kn3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KWOe8ZeWmCii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import basic libraries."
      ],
      "metadata": {
        "id": "jVexnJcJ1iFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ydata_profiling import ProfileReport"
      ],
      "metadata": {
        "id": "6ZdBOLzXmV_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading the dataset\n",
        "\n",
        "The dataset we wanna nitpick apart this week is one pertaining to crabs. Use this link to download it:\n",
        "\n",
        "https://drive.google.com/file/d/14384FUrzE1gB7HWn8GmAJe3hfx6Glv8R/view?usp=sharing\n",
        "\n",
        "Upload it to your Google Drive. Then read it into a variable using the pandas library."
      ],
      "metadata": {
        "id": "jgsYRWHmhQAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset into a variable\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Task1.csv\" ./\n",
        "!ls -l"
      ],
      "metadata": {
        "id": "m8Siqb9knB2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the first 5 rows of this DataFrame to see if it has been stored correctly."
      ],
      "metadata": {
        "id": "uAr01C4mlJZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Task1.csv')\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset shape:\", df.shape)\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "5gNBlroulIw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right, so now you have your entire DataFrame residing in a variable. But again, what even is a DataFrame? Just speed through the below article.\n",
        "\n",
        "https://www.databricks.com/glossary/what-are-dataframes\n",
        "\n"
      ],
      "metadata": {
        "id": "_YMrWRL3idix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#basic EDA\n",
        "\n",
        "Here, we aim to get a basic overview of the dataset.\n"
      ],
      "metadata": {
        "id": "n35a9N5Sld_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the columns in this dataset."
      ],
      "metadata": {
        "id": "VnyHtyu7lyd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "\n",
        "print(\"\\nColumn names:\")\n",
        "for i, col in enumerate(df.columns, 1):\n",
        "    print(f\"{i}. {col}\")"
      ],
      "metadata": {
        "id": "RF0YI22Dnh7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may have noticed that the 'id' column is just indexing the rows in the DataFrame. But we don't really need that, as pandas very neatly handles that for us. So drop that column."
      ],
      "metadata": {
        "id": "sSDgAbBJpyo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the column, then view its first 5 values\n",
        "\n",
        "df = df.drop('id', axis=1)\n",
        "\n",
        "print(\"First 5 rows after dropping 'id' column:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Number of rows: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")"
      ],
      "metadata": {
        "id": "GRINhc60pvll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the the number of rows and columns in this dataset."
      ],
      "metadata": {
        "id": "C-pajIWIl55Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "\n",
        "print(\"DATASET DIMENSIONS\")\n",
        "print(\"=\" * 30)\n",
        "print(f\"Rows: {df.shape[0]:,}\")      # Adds comma formatting for large numbers\n",
        "print(f\"Columns: {df.shape[1]}\")\n",
        "print(f\"Total cells: {df.shape[0] * df.shape[1]:,}\")\n",
        "print(f\"Shape: {df.shape}\")"
      ],
      "metadata": {
        "id": "8N1d8_kamA1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the info() function to get, well, info about it."
      ],
      "metadata": {
        "id": "aQcIiVrcmFNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "bJS3tII7mmBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If done correctly, you'll encounter no null values. How lucky."
      ],
      "metadata": {
        "id": "SaOk9AOzzs5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the statistics of this data? Use describe() function to view them. Google what each of those row headers mean."
      ],
      "metadata": {
        "id": "0WdsqJULmvjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "# Get statistical summary of the dataset\n",
        "print(\"Statistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPLANATION OF DESCRIBE() OUTPUT:\")\n",
        "print(\"=\"*60)\n",
        "print(\"count: Total number of non-null entries\")\n",
        "print(\"mean: Average value of the column\")\n",
        "print(\"std: Standard deviation (measure of spread)\")\n",
        "print(\"min: Minimum value in the column\")\n",
        "print(\"25%: First quartile (25th percentile)\")\n",
        "print(\"50%: Median (50th percentile)\")\n",
        "print(\"75%: Third quartile (75th percentile)\")\n",
        "print(\"max: Maximum value in the column\")"
      ],
      "metadata": {
        "id": "vHDY9fnAnArD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count gives the total number of non null entry"
      ],
      "metadata": {
        "id": "CL_8E-af4MYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "std is the standard devivation\n",
        "\n",
        "* mean doesnot tell about the distribution\n",
        "\n",
        "* example 3,3,3 and 2,3,4 mean is 3 of both but the spread is different\n",
        "\n",
        "* then the variance is used to calcuate spread but as it is square not in the dimension of the data therefore we use std which is square root of the varianace.\n",
        "\n"
      ],
      "metadata": {
        "id": "RRIXesSk4MUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mean is average"
      ],
      "metadata": {
        "id": "89kxxxG04MRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**last 5 rows states about the five-number summary**\n",
        "\n",
        "Min - Lowest value\n",
        "\n",
        "Q1 (25%) - Lower quartile(basically value at 25 percentile)\n",
        "\n",
        "Median (50%) - Middle value\n",
        "\n",
        "Q3 (75%) - Upper quartile(basically value at 75 percentile)\n",
        "\n",
        "Max - Highest value"
      ],
      "metadata": {
        "id": "EHzRH2vZ4MFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function to print all the unique values in the columns of Sex and Age."
      ],
      "metadata": {
        "id": "kZ_ebv5bnhJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "# Function to print unique values in Sex and Age columns\n",
        "def print_unique_values(df, columns):\n",
        "    \"\"\"\n",
        "    Print unique values and their counts for specified columns\n",
        "    \"\"\"\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            unique_vals = df[col].unique()\n",
        "            print(f\"Column: {col}\")\n",
        "            print(f\"   Unique values: {sorted(unique_vals)}\")\n",
        "            print(f\"   Number of unique values: {len(unique_vals)}\")\n",
        "            print(f\"   Value counts:\")\n",
        "            print(df[col].value_counts().sort_index())\n",
        "            print(\"-\" * 50)\n",
        "        else:\n",
        "            print(f\"Column '{col}' not found in DataFrame\")\n",
        "\n",
        "print_unique_values(df, ['Sex', 'Age'])"
      ],
      "metadata": {
        "id": "BnE-2G3BnFGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional verification\n",
        "print(\"Additional column information:\")\n",
        "print(f\"Sex column dtype: {df['Sex'].dtype}\")\n",
        "print(f\"Age column dtype: {df['Age'].dtype}\")\n",
        "\n",
        "# if any missing values in these columns\n",
        "print(f\"\\nMissing values in Sex: {df['Sex'].isnull().sum()}\")\n",
        "print(f\"Missing values in Age: {df['Age'].isnull().sum()}\")"
      ],
      "metadata": {
        "id": "rya7k8ciCDqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create visualizations for the unique values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "\n",
        "if 'Sex' in df.columns:\n",
        "    sex_counts = df['Sex'].value_counts()\n",
        "    ax1.pie(sex_counts.values, labels=sex_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "    ax1.set_title('Distribution of Sex')\n",
        "\n",
        "\n",
        "if 'Age' in df.columns:\n",
        "    age_counts = df['Age'].value_counts().sort_index()\n",
        "    ax2.bar(age_counts.index, age_counts.values)\n",
        "    ax2.set_title('Distribution of Age')\n",
        "    ax2.set_xlabel('Age')\n",
        "    ax2.set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GtjgyOyn9zR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of findings\n",
        "print(\"SUMMARY OF UNIQUE VALUES ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if 'Sex' in df.columns:\n",
        "    print(f\"Sex: {sorted(df['Sex'].unique())} → {len(df['Sex'].unique())} categories\")\n",
        "\n",
        "if 'Age' in df.columns:\n",
        "    print(f\"Age: {sorted(df['Age'].unique())} → {len(df['Age'].unique())} categories\")\n",
        "    print(f\"Age range: {df['Age'].min()} to {df['Age'].max()}\")\n",
        "\n",
        "print(f\"\\nTotal records: {len(df)}\")"
      ],
      "metadata": {
        "id": "5HdG31gJ7-im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List out the number of crabs belonging to each gender."
      ],
      "metadata": {
        "id": "bHbMaSPKyEFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "\n",
        "# Count the number of crabs belonging to each gender category\n",
        "gender_counts = df['Sex'].value_counts()\n",
        "\n",
        "print(\"CRAB GENDER/SEX CATEGORY DISTRIBUTION\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Display all categories\n",
        "for category, count in gender_counts.items():\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"{category}: {count:,} crabs ({percentage:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(f\"Total crabs: {len(df):,}\")\n",
        "\n",
        "# Calculate mature crabs only (excluding 'I' category)\n",
        "mature_crabs = df[df['Sex'].isin(['M', 'F'])]\n",
        "if len(mature_crabs) > 0:\n",
        "    mature_counts = mature_crabs['Sex'].value_counts()\n",
        "    print(f\"\\nMature crabs only (excluding 'I'):\")\n",
        "    for gender, count in mature_counts.items():\n",
        "        pct = (count / len(mature_crabs)) * 100\n",
        "        print(f\"  {gender}: {count:,} crabs ({pct:.2f}%)\")\n",
        "\n",
        "print(f\"\\nDataset balance analysis:\")\n",
        "print(f\"✓ The dataset has {len(gender_counts)} sex categories\")\n",
        "print(f\"✓ 'M' (Male) is the most common category\")\n",
        "print(f\"✓ 'I' likely represents immature/unknown crabs\")\n",
        "print(f\"✓ Distribution is relatively balanced across categories\")"
      ],
      "metadata": {
        "id": "71mfDcbbyTiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your output is correct, you'll find the dataset is decently well-balanced, although it is a bit skewed towards male crabs."
      ],
      "metadata": {
        "id": "FdxzyNmp_Ie6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pandas profiling"
      ],
      "metadata": {
        "id": "X3080G2QhD_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing all the above for each dataset in separate cells gets boring fast. Enter ydata_profiling. You just have to feed a DataFrame to it, and it takes care of basic EDA (and then some more) for you. Resource:\n",
        "\n",
        "https://ydata-profiling.ydata.ai/docs/master/pages/getting_started/quickstart.html\n",
        "\n",
        "Run a Profile Report on our dataframe and just go through it."
      ],
      "metadata": {
        "id": "d_LdQ-m8hGmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "# profile = pp.ProfileReport(df)\n",
        "# profile.to_file(\"report.html\")\n",
        "\n",
        "# Simple and reliable version for Colab\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# Generate report\n",
        "profile = ProfileReport(df, title=\"Crab Dataset Analysis\")\n",
        "profile.to_file(\"crab_report.html\")\n",
        "\n",
        "print(\" Report generated successfully as 'crab_report.html'!\")\n",
        "print(\"Check the file browser on the left to download your report\")"
      ],
      "metadata": {
        "id": "zF-gFEzOh7Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A lot of what we did above manually gets handled automatically. Pretty cool, innit?\n",
        "\n",
        "Also, if you genuinely went through the report, you'll find that some crabs have height as zero. That doesn't make much sense.\n",
        "\n",
        "Drop all these apparently two dimensional crabs from the dataset. Get rid of all rows where height is zero."
      ],
      "metadata": {
        "id": "4Ubhzt3gh-QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the necessary rows as asked above\n",
        "\n",
        "# First, let's see what columns we actually have\n",
        "print(\"Available columns in the dataset:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "print(\"\\n Let's find which column contains height information:\")\n",
        "for col in df.columns:\n",
        "    print(f\"  - {col}\")\n",
        "\n",
        "# Check if there are similar column names (case variations, abbreviations)\n",
        "print(\"\\n Searching for height-related columns...\")\n",
        "height_related = [col for col in df.columns if 'height' in col.lower() or 'hgt' in col.lower()]\n",
        "if height_related:\n",
        "    print(f\"Possible height columns: {height_related}\")\n",
        "else:\n",
        "    print(\"No obvious height column found. Let's check the first few rows:\")\n",
        "    print(df.head())"
      ],
      "metadata": {
        "id": "Xnvy65RwR4NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If done correctly, your DataFrame now will have shape (74027, 9). Check that below."
      ],
      "metadata": {
        "id": "PcrFNZtiToGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "height_column = 'Height'  # Change this to the actual column name\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "\n",
        "# Counting how many rows have height = 0\n",
        "zero_height_count = (df[height_column] == 0).sum()\n",
        "print(f\"Number of crabs with zero {height_column}: {zero_height_count}\")\n",
        "\n",
        "df = df[df[height_column] != 0]\n",
        "\n",
        "print(f\"Dataset shape after removing zero-{height_column} crabs: {df.shape}\")"
      ],
      "metadata": {
        "id": "ZhgQkDFkTntk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as we drop some columns to make index again normal\n",
        "\n",
        "print(f\"Dataset shape before resetting index: {df.shape}\")\n",
        "\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Dataset shape after resetting index: {df.shape}\")\n",
        "\n",
        "\n",
        "expected_shape = (74027, 9)\n",
        "if df.shape == expected_shape:\n",
        "    print(\"SUCCESS! Index reset and shape matches expected (74027, 9)\")\n",
        "else:\n",
        "    print(f\"Shape mismatch. Expected {expected_shape}, got {df.shape}\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with reset index:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "dOCkUNOsQyRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#plotting some stuff out\n",
        "\n",
        "To explore data properly, data visualisation techniques are employed. What that essentially means that we're gonna plot some graphs and glean meaningful insights from them. We use the matplotlib library for this, and seaborn to make it look real pretty, for no one likes an ugly graph.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "00PG10C6q6ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#bar charts"
      ],
      "metadata": {
        "id": "-Y_99EUk-TCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a bar graph to view the average age of each sex. For help, refer:\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/08/understanding-bar-plots-in-python-beginners-guide-to-data-visualization/"
      ],
      "metadata": {
        "id": "47WGjw27ro8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write the logic here before you actually plot the graph\n",
        "# Calculate the average age for each sex category\n",
        "print(\"CALCULATING AVERAGE AGE BY SEX\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Group by Sex and calculate mean age\n",
        "age_by_sex = df.groupby('Sex')['Age'].mean()\n",
        "\n",
        "print(\"Average age for each sex category:\")\n",
        "for sex, avg_age in age_by_sex.items():\n",
        "    print(f\"  {sex}: {avg_age:.2f} years\")\n",
        "\n",
        "print(f\"\\nOverall average age: {df['Age'].mean():.2f} years\")\n",
        "\n",
        "# Additional statistics\n",
        "print(\"\\nAdditional statistics:\")\n",
        "age_stats = df.groupby('Sex')['Age'].agg(['mean', 'std', 'min', 'max'])\n",
        "print(age_stats)"
      ],
      "metadata": {
        "id": "pWCec0zNsley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x axis will contain Sex, and y axis has the average age."
      ],
      "metadata": {
        "id": "Y3ZreZlGzH9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the graph here\n",
        "# Alternative: Using seaborn for better styling\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Create bar plot with seaborn\n",
        "sns.barplot(x=age_by_sex.index, y=age_by_sex.values, palette='viridis')\n",
        "\n",
        "plt.xlabel('Sex', fontsize=12)\n",
        "plt.ylabel('Average Age', fontsize=12)\n",
        "plt.title('Average Age of Crabs by Sex Category', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(age_by_sex.values):\n",
        "    plt.text(i, v + 0.05, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLlvELk5v9uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with humans, it seems that crabs have their female sex having longer lives on average. Still, all genders have a pretty short lifespan. Shame.  "
      ],
      "metadata": {
        "id": "NCeJkyT1xrWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anyways, the above bar graph of Average Age and Sex is not the most comprehensive way to analyse such data."
      ],
      "metadata": {
        "id": "139j-T9Sybfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#box plots"
      ],
      "metadata": {
        "id": "lKgPbxpF_Nbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get what I mean, make a boxplot of Age and Sex. Again, refer to these before you code:\n",
        "\n",
        "https://www.youtube.com/watch?v=Vo-bfTqEFQk\n",
        "\n",
        "https://builtin.com/data-science/boxplot\n",
        "\n"
      ],
      "metadata": {
        "id": "ORZ4MmW-52gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the graph here\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "data = [df[df['Sex'] == 'F']['Age'],\n",
        "        df[df['Sex'] == 'I']['Age'],\n",
        "        df[df['Sex'] == 'M']['Age']]\n",
        "\n",
        "plt.boxplot(data, labels=['Female (F)', 'Immature (I)', 'Male (M)'])\n",
        "plt.xlabel('Sex Category', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Age (years)', fontsize=12, fontweight='bold')\n",
        "plt.title('Age Distribution by Crab Sex Category', fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B5254eI-52Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar charts usually just tell you the count of some items in a dataset. While that is useful, it doesn't really say much about the distribution of those items in that dataset. That's where boxplots come in: to tell you the characteristics of data. For more information:\n",
        "\n",
        "https://www.nature.com/articles/nmeth.2807"
      ],
      "metadata": {
        "id": "T8xY8ns89hpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KDE plots"
      ],
      "metadata": {
        "id": "34EXUQwy_RfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll graph some of the other numeric data with age to try and get more information about it all relates. Display KDE plots of Age, Length, and Weight. For resources about a KDE plot:\n",
        "\n",
        "https://www.youtube.com/watch?v=DCgPRaIDYXA\n",
        "\n",
        "https://datagy.io/seaborn-kdeplot/\n",
        "\n",
        "Don't make three separate cells for each of these plots. All three plots should be visible in a single row."
      ],
      "metadata": {
        "id": "_-ILWXcfyzRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code that yields output similar to the one shown below\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "\n",
        "columns = ['Age', 'Length', 'Weight']\n",
        "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
        "titles = ['Age Distribution', 'Length Distribution', 'Weight Distribution']\n",
        "\n",
        "\n",
        "for i, (col, color, title) in enumerate(zip(columns, colors, titles)):\n",
        "\n",
        "    if col in df.columns:\n",
        "\n",
        "        sns.kdeplot(data=df, x=col, ax=axes[i], fill=True, color=color, alpha=0.7)\n",
        "\n",
        "\n",
        "        axes[i].set_title(f'KDE Plot of {title}', fontsize=14, fontweight='bold')\n",
        "        axes[i].set_xlabel(col, fontsize=12)\n",
        "        axes[i].set_ylabel('Density', fontsize=12)\n",
        "        axes[i].grid(alpha=0.3)\n",
        "\n",
        "\n",
        "        mean_val = df[col].mean()\n",
        "        median_val = df[col].median()\n",
        "        axes[i].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
        "        axes[i].axvline(median_val, color='blue', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
        "        axes[i].legend()\n",
        "    else:\n",
        "        axes[i].text(0.5, 0.5, f\"Column '{col}' not found\",\n",
        "                    ha='center', va='center', transform=axes[i].transAxes, fontsize=12)\n",
        "        axes[i].set_title(f'Missing: {col}', fontsize=14)\n",
        "\n",
        "\n",
        "plt.suptitle('Kernel Density Estimation (KDE) Plots of Crab Measurements',\n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FlLGlxui0ONc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#scatter plots"
      ],
      "metadata": {
        "id": "wylisMOY_3-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a scatterplot between Age and Diameter. Resources for the same:\n",
        "\n",
        "https://www.youtube.com/watch?v=4yz4cMXCkuw\n",
        "\n",
        "https://www.cuemath.com/data/scatter-plot/"
      ],
      "metadata": {
        "id": "m-hkpXjQBkCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the graph here\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "\n",
        "sns.scatterplot(data=df, x='Age', y='Diameter', hue='Sex',\n",
        "                palette={'F': 'red', 'M': 'blue', 'I': 'green'},\n",
        "                alpha=0.7, s=60)\n",
        "\n",
        "\n",
        "sns.regplot(data=df, x='Age', y='Diameter',\n",
        "            scatter=False, ci=None, line_kws={'color': 'black', 'linestyle': '--'})\n",
        "\n",
        "plt.xlabel('Age (years)', fontsize=13, fontweight='bold')\n",
        "plt.ylabel('Diameter', fontsize=13, fontweight='bold')\n",
        "plt.title('Relationship Between Age and Diameter in Crabs', fontsize=15, fontweight='bold')\n",
        "\n",
        "\n",
        "correlation = df['Age'].corr(df['Diameter'])\n",
        "plt.text(0.02, 0.98, f'Pearson Correlation: {correlation:.3f}',\n",
        "         transform=plt.gca().transAxes, fontsize=12,\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\"))\n",
        "\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(title='Sex Category', title_fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "STSreAqp_5xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyMvDP-iHg7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# some more complex analysis"
      ],
      "metadata": {
        "id": "u2N1C7mBIS5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a function called corr(). Resource:\n",
        "\n",
        "https://data36.com/correlation-definition-calculation-corr-pandas/\n",
        "\n"
      ],
      "metadata": {
        "id": "YixxeCxVIYW_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EMxDV4k2H0dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "\n",
        "print(\"CORRELATION MATRIX ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "correlation_matrix = df.corr(numeric_only=True)\n",
        "\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FORMATTED CORRELATION MATRIX\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(correlation_matrix.round(3))"
      ],
      "metadata": {
        "id": "LOKZiSKwIXLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you've been paying attention, the Profile Report above already took care of this. This table basically tells you how every column correlate with each other. Closer the number is to 1, the more they mirror each other."
      ],
      "metadata": {
        "id": "XuU2v1CuJmNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this report, it can be seen that Weight is extremely highly correlated with each of shucked weight, viscera weight and shell weight.\n",
        "\n",
        "To actually understand what this means, we first need to know what all this crab jargon actually is. So, on Googling, you will discover the following meanings:\n",
        "\n",
        "*   Weight - total teight\n",
        "*   Shucked - weight of meat only\n",
        "*   Viscera - gut weight, after bleeding\n",
        "*   Shell - weight after being dried\n",
        "\n",
        "Well, those are some pretty disgusting and gory definitions.\n",
        "\n",
        "Moving past that, we here find that some weight statistics is lost. What about the other potential body parts of a crab? Maybe we need them to accurately predict its (apparently very short) lifespan? Maybe it is actually needed in some future model we choose to implement?\n",
        "\n",
        "So, make a new column called \"Lost Weight\". Use the following formula to populate every row of it:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Weight - (Shucked + Viscera + Shell)\n",
        "```\n"
      ],
      "metadata": {
        "id": "iuNkvl5fKQ2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If this operation gives a value of Lost Weight that is less than or equal to zero, then assign zero to that row's Lost Weight value. Otherwise, assign one to it."
      ],
      "metadata": {
        "id": "xh-BMhAzUNoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, ensure that this column is added in between Shell Weight and Age."
      ],
      "metadata": {
        "id": "K3gvAHbsVOHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "\n",
        "print(\"CREATING 'LOST WEIGHT' COLUMN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "lost_weight = df['Weight'] - (df['Shucked Weight'] + df['Viscera Weight'] + df['Shell Weight'])\n",
        "\n",
        "df['Lost Weight'] = lost_weight.apply(lambda x: 0 if x <= 0 else 1)\n",
        "\n",
        "print(f\"Lost Weight column created successfully!\")\n",
        "print(f\"Values distribution:\")\n",
        "print(df['Lost Weight'].value_counts().sort_index())\n",
        "\n",
        "current_columns = df.columns.tolist()\n",
        "print(f\"\\nOriginal column order: {current_columns}\")\n",
        "\n",
        "shell_weight_idx = current_columns.index('Shell Weight')\n",
        "age_idx = current_columns.index('Age')\n",
        "\n",
        "print(f\"Shell Weight index: {shell_weight_idx}\")\n",
        "print(f\"Age index: {age_idx}\")\n",
        "\n",
        "current_columns.remove('Lost Weight')\n",
        "\n",
        "new_columns = (current_columns[:shell_weight_idx+1] +\n",
        "               ['Lost Weight'] +\n",
        "               current_columns[shell_weight_idx+1:])\n",
        "\n",
        "df = df[new_columns]\n",
        "\n",
        "print(f\"\\nNew column order: {df.columns.tolist()}\")\n",
        "print(f\"Dataset shape: {df.shape}\")"
      ],
      "metadata": {
        "id": "aWIYzg91Ji0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the new column placement and values\n",
        "print(\"VERIFICATION OF 'LOST WEIGHT' COLUMN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check the column order\n",
        "print(\"Current column order:\")\n",
        "for i, col in enumerate(df.columns):\n",
        "    print(f\"  {i}. {col}\")\n",
        "\n",
        "# Verify Lost Weight is between Shell Weight and Age\n",
        "shell_weight_pos = df.columns.get_loc('Shell Weight')\n",
        "lost_weight_pos = df.columns.get_loc('Lost Weight')\n",
        "age_pos = df.columns.get_loc('Age')\n",
        "\n",
        "print(f\"\\nPosition verification:\")\n",
        "print(f\"  Shell Weight: position {shell_weight_pos}\")\n",
        "print(f\"  Lost Weight: position {lost_weight_pos}\")\n",
        "print(f\"  Age: position {age_pos}\")\n",
        "\n",
        "if shell_weight_pos < lost_weight_pos < age_pos:\n",
        "    print(\"SUCCESS: Lost Weight is correctly placed between Shell Weight and Age!\")\n",
        "else:\n",
        "    print(\"ERROR: Column placement is incorrect!\")\n",
        "\n",
        "# Show value distribution\n",
        "print(f\"\\nLost Weight value counts:\")\n",
        "print(df['Lost Weight'].value_counts().sort_index())\n",
        "\n",
        "# Show first few rows with the new column\n",
        "print(f\"\\nFirst 5 rows with new column:\")\n",
        "print(df[['Shell Weight', 'Lost Weight', 'Age']].head())\n"
      ],
      "metadata": {
        "id": "TfMiPDwzNeC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed analysis of weight components\n",
        "print(\"DETAILED WEIGHT COMPONENTS ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "actual_lost_weight = df['Weight'] - (df['Shucked Weight'] + df['Viscera Weight'] + df['Shell Weight'])\n",
        "\n",
        "print(\"Weight Components Summary:\")\n",
        "print(f\"Total Weight - mean: {df['Weight'].mean():.2f}\")\n",
        "print(f\"Shucked Weight - mean: {df['Shucked Weight'].mean():.2f}\")\n",
        "print(f\"Viscera Weight - mean: {df['Viscera Weight'].mean():.2f}\")\n",
        "print(f\"Shell Weight - mean: {df['Shell Weight'].mean():.2f}\")\n",
        "print(f\"Actual Lost Weight - mean: {actual_lost_weight.mean():.2f}\")\n",
        "\n",
        "print(f\"\\nLost Weight Statistics:\")\n",
        "print(f\"Crabs with weight loss (Lost Weight = 1): {(df['Lost Weight'] == 1).sum()}\")\n",
        "print(f\"Crabs with no weight loss (Lost Weight = 0): {(df['Lost Weight'] == 0).sum()}\")\n",
        "print(f\"Percentage with weight loss: {(df['Lost Weight'] == 1).sum() / len(df) * 100:.2f}%\")\n",
        "\n",
        "# Show some examples\n",
        "print(f\"\\nExamples of crabs with weight discrepancies:\")\n",
        "sample = df[actual_lost_weight != 0][['Weight', 'Shucked Weight', 'Viscera Weight', 'Shell Weight', 'Lost Weight']].head(10)\n",
        "print(sample)"
      ],
      "metadata": {
        "id": "Gv_IHB17KvAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see how the crabs having no Lost Weight compare with those having some with respect to age, lets draw a violin plot. Resources:\n",
        "\n",
        "https://www.youtube.com/watch?v=PNNLefP974M\n",
        "\n",
        "https://seaborn.pydata.org/generated/seaborn.violinplot.html\n",
        "\n",
        "Code it below now. Here, x is the Lost Weight, and y is the Age."
      ],
      "metadata": {
        "id": "x67-hzNzW1Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the graph here\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "df_plot = df.copy()\n",
        "df_plot['Lost Weight Str'] = df_plot['Lost Weight'].astype(str)\n",
        "\n",
        "sns.violinplot(x='Lost Weight Str', y='Age', data=df_plot,\n",
        "               palette={'0': 'lightgreen', '1': 'lightcoral'})\n",
        "\n",
        "plt.xlabel('Lost Weight Category', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Age (years)', fontsize=12, fontweight='bold')\n",
        "plt.title('Age Distribution Comparison: Crabs With vs Without Weight Discrepancies',\n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Improve x-axis labels\n",
        "plt.xticks(ticks=[0, 1], labels=['No Weight Loss\\n(Lost Weight = 0)', 'Weight Loss\\n(Lost Weight = 1)'])\n",
        "\n",
        "# Add sample size annotations\n",
        "count_0 = len(df[df['Lost Weight'] == 0])\n",
        "count_1 = len(df[df['Lost Weight'] == 1])\n",
        "\n",
        "plt.text(0, plt.ylim()[1] * 0.95, f'n = {count_0:,}',\n",
        "         ha='center', va='top', fontweight='bold', fontsize=11,\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
        "plt.text(1, plt.ylim()[1] * 0.95, f'n = {count_1:,}',\n",
        "         ha='center', va='top', fontweight='bold', fontsize=11,\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
        "\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WPeEjrXSYbue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#make a plot of your own choosing!"
      ],
      "metadata": {
        "id": "UMYZ_LxQDMG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a link to the gallery of various plots available in seaborn.\n",
        "\n",
        "https://seaborn.pydata.org/examples/index.html\n",
        "\n",
        "You have free rein to make any type of graph (that should not be what we have exactly done above), between any parameters you want to compare. Make it real eye candy to look at, and also below that plot write what relevant insight you obtained from it."
      ],
      "metadata": {
        "id": "6onzxmQuDkus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creativity batao\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "scatter = ax.scatter(df['Length'], df['Diameter'], df['Height'],\n",
        "                    c=df['Sex'].map({'F': 0, 'M': 1, 'I': 2}),\n",
        "                    cmap='viridis', alpha=0.6, s=20)\n",
        "\n",
        "ax.set_xlabel('Length', fontsize=12, fontweight='bold', labelpad=10)\n",
        "ax.set_ylabel('Diameter', fontsize=12, fontweight='bold', labelpad=10)\n",
        "ax.set_zlabel('Height', fontsize=12, fontweight='bold', labelpad=10)\n",
        "\n",
        "ax.set_title('3D Crab Morphology Space\\nLength × Diameter × Height by Sex',\n",
        "            fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Create custom legend\n",
        "legend_elements = [plt.Line2D([0], [0], marker='o', color='w',\n",
        "                             markerfacecolor='yellow', markersize=8, label='Female (F)'),\n",
        "                  plt.Line2D([0], [0], marker='o', color='w',\n",
        "                             markerfacecolor='purple', markersize=8, label='Male (M)'),\n",
        "                  plt.Line2D([0], [0], marker='o', color='w',\n",
        "                             markerfacecolor='cyan', markersize=8, label='Immature (I)')]\n",
        "\n",
        "ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "# Rotate for better view\n",
        "ax.view_init(elev=20, azim=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8lZ7WbrbDkEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This heatmap shows the correlation of different features with \"Age\". Key insights:\n",
        "\n",
        "1. **Shell Weight** has the highest correlation with **Age** (0.66), making it a strong predictor.\n",
        "2. **Height**, **Diameter**, **Length**, and **Weight** have moderate correlations, making them useful for prediction.\n",
        "3. **Lost_Weight** has a low correlation (0.15), suggesting it may be less useful as a feature.\n",
        "\n",
        " It helps quickly identify important features for machine learning by showing correlations with the target variable.\n"
      ],
      "metadata": {
        "id": "qLxgKqzPTYc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Targeted Correlation Heatmap focusing on Age relationships\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "corr_matrix = df.corr(numeric_only=True)\n",
        "\n",
        "age_correlations = corr_matrix['Age'].sort_values(ascending=False)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "colors = plt.cm.RdYlBu_r((age_correlations.values + 1) / 2)  # Color scale from -1 to 1\n",
        "\n",
        "bars = plt.barh(range(len(age_correlations)), age_correlations.values, color=colors, alpha=0.7)\n",
        "plt.yticks(range(len(age_correlations)), age_correlations.index, fontsize=11)\n",
        "plt.xlabel('Correlation Coefficient with Age', fontsize=12, fontweight='bold')\n",
        "plt.title('Feature Correlations with Crab Age', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "for i, (bar, value) in enumerate(zip(bars, age_correlations.values)):\n",
        "    plt.text(value + 0.01 * (1 if value >= 0 else -1), i,\n",
        "             f'{value:.3f}', va='center', fontweight='bold', fontsize=10,\n",
        "             color='black' if abs(value) < 0.5 else 'white')\n",
        "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
        "\n",
        "plt.text(0.02, 0.02, 'Strong Negative ← → Strong Positive',\n",
        "         transform=plt.gca().transAxes, fontsize=10,\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
        "\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jAVq4-qUOAG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#one hot encoding"
      ],
      "metadata": {
        "id": "fc5m48dMWkST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning algorithms can only crunch numbers. Give it a string or text input, and it self-annihilates by throwing an error. To handle this, we use a technique called one hot encoding. Read up on it here:\n",
        "\n",
        "https://datagy.io/pandas-get-dummies/\n",
        "\n",
        "Then, apply it to the column titled \"Sex.\""
      ],
      "metadata": {
        "id": "awF6yCWxXGDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "# Apply One-Hot Encoding to the Sex column\n",
        "print(\"APPLYING ONE-HOT ENCODING TO 'SEX' COLUMN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"Before one-hot encoding:\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nUnique values in 'Sex' column: {df['Sex'].unique()}\")\n",
        "print(f\"Value counts:\\n{df['Sex'].value_counts()}\")\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=['Sex'], prefix='Sex')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"After one-hot encoding:\")\n",
        "print(f\"Dataset shape: {df_encoded.shape}\")\n",
        "print(f\"New columns: {df_encoded.columns.tolist()}\")\n",
        "\n",
        "sex_columns = [col for col in df_encoded.columns if col.startswith('Sex_')]\n",
        "print(f\"\\nOne-hot encoded columns: {sex_columns}\")\n",
        "\n",
        "print(f\"\\nFirst 5 rows with one-hot encoding:\")\n",
        "print(df_encoded[['Sex_F', 'Sex_I', 'Sex_M']].head(10))\n",
        "\n",
        "print(f\"\\nSUCCESS: One-hot encoding completed!\")\n",
        "print(f\"   • Original 'Sex' column removed\")\n",
        "print(f\"   • New columns created: {sex_columns}\")\n",
        "print(f\"   • Each row now has 1 in one column and 0 in others\")"
      ],
      "metadata": {
        "id": "pALMgRtPXysz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QaNLc-kdSehO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "33iLRCBuS6Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If correctly implemented, you will observe three new columns are added, namely, \"Sex_F\", \"Sex_I\" and \"Sex_M.\" The old \"Sex\" column is now gone."
      ],
      "metadata": {
        "id": "NQvibNzWYUKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#normalisation and standardisation"
      ],
      "metadata": {
        "id": "4w5Ss5UXTtT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prevent some data features from dominating the model training process, we implement the above two feature scaling techniques."
      ],
      "metadata": {
        "id": "NTZGTA_zWxDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go through the below resource:\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/"
      ],
      "metadata": {
        "id": "OWZkOtGOTxIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalise the dataset."
      ],
      "metadata": {
        "id": "DjhPYc3DVvZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "print(\"APPLYING NORMALIZATION (MIN-MAX SCALING)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"Before Normalization:\")\n",
        "print(\"Dataset shape:\", df_encoded.shape)\n",
        "print(\"\\nOriginal data statistics:\")\n",
        "print(df_encoded.describe().round(3))\n",
        "\n",
        "numeric_columns = df_encoded.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\nNumeric columns to normalize: {numeric_columns}\")\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df_normalized = df_encoded.copy()\n",
        "df_normalized[numeric_columns] = scaler.fit_transform(df_encoded[numeric_columns])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"After Normalization:\")\n",
        "print(\"\\nNormalized data statistics:\")\n",
        "print(df_normalized.describe().round(3))\n",
        "\n",
        "print(f\"\\nVERIFICATION OF NORMALIZATION:\")\n",
        "print(f\"• All values are now between 0 and 1\")\n",
        "print(f\"• Minimum values: {df_normalized[numeric_columns].min().min():.3f}\")\n",
        "print(f\"• Maximum values: {df_normalized[numeric_columns].max().max():.3f}\")\n",
        "\n",
        "sample_columns = ['Length', 'Diameter', 'Weight', 'Age']\n",
        "print(f\"\\nBEFORE vs AFTER NORMALIZATION (Sample):\")\n",
        "comparison = pd.DataFrame({\n",
        "    'Original_Min': df_encoded[sample_columns].min(),\n",
        "    'Original_Max': df_encoded[sample_columns].max(),\n",
        "    'Normalized_Min': df_normalized[sample_columns].min(),\n",
        "    'Normalized_Max': df_normalized[sample_columns].max()\n",
        "})\n",
        "print(comparison.round(3))"
      ],
      "metadata": {
        "id": "RVHpmBEqVuoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AU4aVgQRTeoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For standardisation, bear in mind that the one hot encoded columns are not standardised. They are categorical in nature, so it makes no sense to shoehorn them into any type of distribution at all.\n",
        "\n",
        "But, its ok to normalise them, as it will be scaled down to values between 0 and 1, which is the range in which they already exist anyways. Normalisation doesn't affect them."
      ],
      "metadata": {
        "id": "sx1SHNW5Z-PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# one hot encode the Sex column before running the next cell\n",
        "print(\" ONE-HOT ENCODING 'SEX' COLUMN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"Before one-hot encoding:\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"Sex column unique values: {df['Sex'].unique()}\")\n",
        "df_encoded = pd.get_dummies(df, columns=['Sex'], prefix='Sex')\n",
        "\n",
        "print(\"\\nAfter one-hot encoding:\")\n",
        "print(f\"Dataset shape: {df_encoded.shape}\")\n",
        "print(f\"New columns: {df_encoded.columns.tolist()}\")\n",
        "sex_columns = [col for col in df_encoded.columns if col.startswith('Sex_')]\n",
        "print(f\"\\nOne-hot encoded columns: {sex_columns}\")\n",
        "print(f\"First 5 rows of encoded columns:\")\n",
        "print(df_encoded[sex_columns].head())\n",
        "\n",
        "print(f\"\\nOne-hot encoding completed successfully!\")"
      ],
      "metadata": {
        "id": "bKS68cnxbTK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"APPLYING NORMALIZATION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"Before Normalization - Dataset info:\")\n",
        "print(f\"Shape: {df_encoded.shape}\")\n",
        "print(f\"All columns: {df_encoded.columns.tolist()}\")\n",
        "\n",
        "numeric_columns = df_encoded.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\nAll numeric columns to normalize: {numeric_columns}\")\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_normalized = df_encoded.copy()\n",
        "\n",
        "df_normalized[numeric_columns] = scaler.fit_transform(df_encoded[numeric_columns])\n",
        "\n",
        "print(\"\\nAfter Normalization:\")\n",
        "print(f\"Dataset shape: {df_normalized.shape}\")\n",
        "\n",
        "print(f\"\\nNORMALIZATION VERIFICATION:\")\n",
        "print(f\"All numeric values are now in range [0, 1]\")\n",
        "print(f\"Minimum value: {df_normalized[numeric_columns].min().min():.6f}\")\n",
        "print(f\"Maximum value: {df_normalized[numeric_columns].max().max():.6f}\")\n",
        "\n",
        "print(f\"\\nONE-HOT ENCODED COLUMNS AFTER NORMALIZATION:\")\n",
        "print(\"(They remain as 0 or 1 since they were already in this range)\")\n",
        "print(df_normalized[sex_columns].head())"
      ],
      "metadata": {
        "id": "JJuSp-U_51y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEMONSTRATION: Why one-hot encoded columns are unaffected by normalization\n",
        "print(\"WHY ONE-HOT ENCODED COLUMNS ARE UNAFFECTED BY NORMALIZATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "#mathematical reason\n",
        "sample_sex_col = 'Sex_F'\n",
        "\n",
        "print(f\"Analysis of '{sample_sex_col}' column:\")\n",
        "print(f\"Original min value: {df_encoded[sample_sex_col].min()}\")\n",
        "print(f\"Original max value: {df_encoded[sample_sex_col].max()}\")\n",
        "\n",
        "# Min-Max normalization formula: (x - min) / (max - min)\n",
        "# For one-hot encoded columns: min=0, max=1\n",
        "# So: (x - 0) / (1 - 0) = x / 1 = x\n",
        "\n",
        "print(f\"\\nNORMALIZATION CALCULATION:\")\n",
        "print(f\"Formula: (x - min) / (max - min)\")\n",
        "print(f\"For one-hot: (x - 0) / (1 - 0) = x\")\n",
        "print(f\"So values remain unchanged!\")\n",
        "\n",
        "print(f\"\\nVERIFICATION:\")\n",
        "print(f\"Original '{sample_sex_col}' values: {df_encoded[sample_sex_col].unique()}\")\n",
        "print(f\"Normalized '{sample_sex_col}' values: {df_normalized[sample_sex_col].unique()}\")\n",
        "\n",
        "print(f\"\\nCONCLUSION:\")\n",
        "print(\"One-hot encoded columns are already in [0,1] range\")\n",
        "print(\"Normalization doesn't change their values\")\n",
        "print(\"They remain perfectly suitable for machine learning\")"
      ],
      "metadata": {
        "id": "E29BkFRT6mfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINAL DATASET OVERVIEW\n",
        "print(\"FINAL PREPROCESSED DATASET OVERVIEW\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"Dataset Summary:\")\n",
        "print(f\"Shape: {df_normalized.shape}\")\n",
        "print(f\"Columns: {df_normalized.columns.tolist()}\")\n",
        "\n",
        "print(f\"\\nData Types:\")\n",
        "print(df_normalized.dtypes)\n",
        "\n",
        "print(f\"\\nValue Ranges After Normalization:\")\n",
        "for col in ['Length', 'Diameter', 'Weight', 'Age', 'Sex_F', 'Sex_I', 'Sex_M']:\n",
        "    if col in df_normalized.columns:\n",
        "        min_val = df_normalized[col].min()\n",
        "        max_val = df_normalized[col].max()\n",
        "        print(f\"  {col}: {min_val:.3f} to {max_val:.3f}\")\n",
        "\n",
        "print(f\"\\nPREPROCESSING COMPLETE!\")\n",
        "print(\"• One-hot encoding: done\")\n",
        "print(\"• Normalization:  dpne\")\n",
        "print(\"• Data ready for machine learning: done\")"
      ],
      "metadata": {
        "id": "Ygshq9Jr61Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardise df_std such that the one hot label encoded columns aren't affected."
      ],
      "metadata": {
        "id": "uuE-EjCoeo88"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSAIIAkG7FsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DBZL2bD4_Luf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"Standardizing numerical columns (excluding one-hot encoded columns)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"Before standardization:\")\n",
        "print(f\"Dataset shape: {df_encoded.shape}\")\n",
        "\n",
        "numeric_columns = df_encoded.select_dtypes(include=[np.number]).columns.tolist()\n",
        "one_hot_columns = [col for col in df_encoded.columns if col.startswith('Sex_')]\n",
        "numerical_columns = [col for col in numeric_columns if col not in one_hot_columns]\n",
        "\n",
        "print(f\"Numerical columns to standardize: {numerical_columns}\")\n",
        "print(f\"One-hot columns to preserve: {one_hot_columns}\")\n",
        "\n",
        "df_std = df_encoded.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_std[numerical_columns] = scaler.fit_transform(df_encoded[numerical_columns])\n",
        "\n",
        "print(\"\\nAfter standardization:\")\n",
        "print(f\"Dataset shape: {df_std.shape}\")\n",
        "\n",
        "print(\"\\nStandardization verification:\")\n",
        "print(\"Numerical columns (mean ~0, std ~1):\")\n",
        "numerical_stats = df_std[numerical_columns].describe()\n",
        "print(numerical_stats.loc[['mean', 'std']].round(3))\n",
        "\n",
        "if one_hot_columns:\n",
        "    print(\"\\nOne-hot columns (unchanged):\")\n",
        "    one_hot_stats = df_std[one_hot_columns].describe()\n",
        "    print(one_hot_stats.round(3))\n",
        "\n",
        "print(\"\\nStandardization completed successfully\")"
      ],
      "metadata": {
        "id": "hfJIvTEcZ72W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aMYD_SV2_VVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA5zCHCX_Hk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Compulsory: You can research on the topic of One Hot Label Encoding vs Label Encoding only if you are done with the task. :)**"
      ],
      "metadata": {
        "id": "paHIWttgczcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encoding vs Label Encoding Comparison\n",
        "\n",
        "print(\"One Hot Encoding vs Label Encoding\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"ONE HOT ENCODING (Current Approach):\")\n",
        "print(\"- Creates separate binary column for each category\")\n",
        "print(\"- Example: Sex_F, Sex_I, Sex_M columns\")\n",
        "print(\"- No ordinal relationship assumed\")\n",
        "print(\"- Prevents false ordinal relationships\")\n",
        "print(\"- Increases dimensionality (k columns for k categories)\")\n",
        "print(\"- Preferred for nominal categorical data\")\n",
        "\n",
        "print(\"\\nLABEL ENCODING (Alternative):\")\n",
        "print(\"- Assigns integer to each category (F=0, I=1, M=2)\")\n",
        "print(\"- Single column remains\")\n",
        "print(\"- May imply ordinal relationship where none exists\")\n",
        "print(\"- Algorithms might misinterpret order as meaningful\")\n",
        "print(\"- Can work for tree-based models\")\n",
        "print(\"- Risky for linear models, distance-based algorithms\")\n",
        "\n",
        "print(\"\\nCURRENT DATASET - One Hot Encoding Applied:\")\n",
        "print(f\"Original 'Sex' column replaced with: {one_hot_columns}\")\n",
        "print(\"Each crab has exactly one '1' across these three columns\")\n",
        "\n",
        "print(\"\\nWHY ONE HOT ENCODING FOR THIS DATASET:\")\n",
        "print(\"- Sex categories (F, I, M) have no natural order\")\n",
        "print(\"- No meaningful 'distance' between Male and Female\")\n",
        "print(\"- Prevents model from assuming M > I > F\")\n",
        "print(\"- Standard practice for nominal categorical variables\")\n",
        "\n",
        "print(\"\\nWHEN TO USE LABEL ENCODING:\")\n",
        "print(\"- Categories have natural order (Low, Medium, High)\")\n",
        "print(\"- Tree-based algorithms that don't assume ordinality\")\n",
        "print(\"- Dealing with high cardinality features\")\n",
        "print(\"- When dimensionality reduction is critical\")"
      ],
      "metadata": {
        "id": "XeScBgZ5IlLo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}